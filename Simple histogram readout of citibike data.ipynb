{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import dp4gp_datasets\n",
    "import dp4gp\n",
    "import random\n",
    "import numpy as np\n",
    "import GPy\n",
    "import dp4gp_histogram\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def get_citibike_data():\n",
    "    allcb = dp4gp_datasets.load_citibike(station=None)\n",
    "    subcb = allcb[allcb['usertype']=='Subscriber']\n",
    "\n",
    "    cb = subcb.ix[random.sample(subcb.index, 5000)]\n",
    "    inputs = np.c_[cb['start station latitude'],cb['end station latitude'],cb['start station longitude'],cb['end station longitude']]\n",
    "    ys = cb['tripduration'].values\n",
    "    \n",
    "    return inputs, ys\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "import dp4gp\n",
    "import GPy\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "import sys\n",
    "import scipy\n",
    "from scipy.stats import multivariate_normal\n",
    "from scipy.optimize import minimize\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def bin_data(Xtest,X,step,ys):\n",
    "    \"\"\"\n",
    "    Bin data X into equally sized bins defined by Xtest and step.\n",
    "    Xtest is the coordinates of the corner of each bin.\n",
    "    step is a vector of step sizes.\n",
    "    ys are the outputs (to be summed and averaged)\n",
    "    \n",
    "    Returns:\n",
    "    bincounts\n",
    "    bintotals\n",
    "    binaverages = bintotals/bincounts\n",
    "    \"\"\"\n",
    "    bintotals = np.zeros(Xtest.shape[0])\n",
    "    bincounts = np.zeros(Xtest.shape[0])\n",
    "    for i,tile in enumerate(Xtest): #loop through the tiles\n",
    "        for x,y in zip(X,ys): #loop through the data\n",
    "            intile = True\n",
    "            for tiled,xd,s in zip(tile,x,step): #loop through the dimensions of the current tile, data and step\n",
    "                if (xd<tiled) or (xd>tiled+s):\n",
    "                    intile = False\n",
    "                    break\n",
    "            if intile:\n",
    "                bintotals[i]+=y\n",
    "                bincounts[i]+=1\n",
    "    binaverages = bintotals/bincounts\n",
    "    return bincounts, bintotals, binaverages\n",
    "\n",
    "class DPGP_histogram(dp4gp.DPGP):\n",
    "    \"\"\"Using the histogram method\"\"\"\n",
    "    \n",
    "    def __init__(self,sens,epsilon,delta):      \n",
    "        super(DPGP_histogram, self).__init__(None,sens,epsilon,delta)\n",
    "\n",
    "    def prepare_model(self,Xtest,X,step,ys,variances=1.0,lengthscale=1):\n",
    "        \"\"\"\n",
    "        Prepare the model, ready for making predictions\"\"\"\n",
    "        bincounts, bintotals, binaverages = bin_data(Xtest,X,step,ys)\n",
    "        sens_per_bin = self.sens/bincounts\n",
    "        c = np.sqrt(2*np.log(1.25/self.delta)) #1.25 or 2 over delta?\n",
    "        bin_sigma = c*sens_per_bin/self.epsilon #noise standard deviation to add to each bin\n",
    "        #add DP noise to the binaverages\n",
    "        dp_binaverages=binaverages+np.random.randn(binaverages.shape[0])*bin_sigma\n",
    "\n",
    "        #we need to build the input for the integral kernel\n",
    "        newXtest = np.zeros([Xtest.shape[0],2*Xtest.shape[1]])\n",
    "        newXtest[:,0::2] = Xtest+step\n",
    "        newXtest[:,1::2] = Xtest\n",
    "\n",
    "        #we don't want outputs that have no training data in.\n",
    "        empty = np.isnan(dp_binaverages)\n",
    "        dp_binaverages[empty] = 0 #we'll make those averages zero\n",
    "\n",
    "        self.Xtest = newXtest\n",
    "        self.dp_binaverages = dp_binaverages\n",
    "     \n",
    "    def draw_prediction_samples(self,Xtest,N=1):\n",
    "        assert N==1, \"DPGP_histogram only returns one DP prediction sample (you will need to rerun prepare_model to get an additional sample)\"\n",
    "    \n",
    "        #return mean+self.meanoffset, cov"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_hist_prediction(training_inputs, training_ys, test_inputs, sens, eps, delta,noise,modvar,kernval,kern_ls,steps):\n",
    "    Xtest, free_inputs, step = dp4gp.compute_Xtest(training_inputs,steps=steps)\n",
    "    print step\n",
    "    dpgp = dp4gp_histogram.DPGP_histogram(sens,eps,delta)\n",
    "    dpgp.prepare_model(Xtest,training_inputs,step,training_ys,lengthscale=kern_ls)\n",
    "    preds, cov = dpgp.draw_prediction_samples(test_inputs)\n",
    "    return preds, cov\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Steps = 3, eps = 0.2\n",
      "[ 0.04332076  0.04332076  0.03489734  0.03489734]\n",
      "Steps = 3, eps = 0.5\n",
      "[ 0.04332076  0.04332076  0.03489734  0.03489734]\n",
      "Steps = 3, eps = 1.0\n",
      "[ 0.04332076  0.04332076  0.03489734  0.03489734]\n",
      "Steps = 3, eps = 1000.0\n",
      "[ 0.04332076  0.04332076  0.03489734  0.03489734]\n",
      "Steps = 6, eps = 0.2\n",
      "[ 0.02166038  0.02166038  0.01744867  0.01744867]\n",
      "Steps = 6, eps = 0.5\n",
      "[ 0.02166038  0.02166038  0.01744867  0.01744867]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-70-e3ceae61e2c7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     36\u001b[0m             \u001b[0mlabels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m\"Histogram\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     37\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 38\u001b[1;33m             \u001b[0mpreds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcov\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_hist_prediction\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtraining_inputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtraining_ys\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtest_inputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0msens\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0meps\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0.01\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m10.0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1.0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkernvar\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkern_ls\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msteps\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     39\u001b[0m             \u001b[0mRMSE\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_ys\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mpreds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m**\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     40\u001b[0m             \u001b[0mresults\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0msteps\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0meps\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;34m'label'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlabel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'preds'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mpreds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'cov'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mcov\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'RMSE'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mRMSE\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'ys_std'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mys_std\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-69-946c17ae4398>\u001b[0m in \u001b[0;36mget_hist_prediction\u001b[1;34m(training_inputs, training_ys, test_inputs, sens, eps, delta, noise, modvar, kernval, kern_ls, steps)\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[1;32mprint\u001b[0m \u001b[0mstep\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mdpgp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdp4gp_histogram\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDPGP_histogram\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msens\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0meps\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdelta\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m     \u001b[0mdpgp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprepare_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mXtest\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtraining_inputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtraining_ys\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlengthscale\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mkern_ls\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m     \u001b[0mpreds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcov\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdpgp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdraw_prediction_samples\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_inputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mpreds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcov\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/lionfish/Documents/Research/dp/dp4gp_histogram.pyc\u001b[0m in \u001b[0;36mprepare_model\u001b[1;34m(self, Xtest, X, step, ys, variances, lengthscale)\u001b[0m\n\u001b[0;32m     46\u001b[0m         \"\"\"\n\u001b[0;32m     47\u001b[0m         Prepare the model, ready for making predictions\"\"\"\n\u001b[1;32m---> 48\u001b[1;33m         \u001b[0mbincounts\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbintotals\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbinaverages\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbin_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mXtest\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mys\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     49\u001b[0m         \u001b[0msens_per_bin\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msens\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mbincounts\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     50\u001b[0m         \u001b[0mc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1.25\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdelta\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#1.25 or 2 over delta?\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/lionfish/Documents/Research/dp/dp4gp_histogram.pyc\u001b[0m in \u001b[0;36mbin_data\u001b[1;34m(Xtest, X, step, ys)\u001b[0m\n\u001b[0;32m     27\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mys\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;31m#loop through the data\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m             \u001b[0mintile\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 29\u001b[1;33m             \u001b[1;32mfor\u001b[0m \u001b[0mtiled\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mxd\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0ms\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtile\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;31m#loop through the dimensions of the current tile, data and step\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     30\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mxd\u001b[0m\u001b[1;33m<\u001b[0m\u001b[0mtiled\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mxd\u001b[0m\u001b[1;33m>\u001b[0m\u001b[0mtiled\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m                     \u001b[0mintile\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "vs = []\n",
    "for its in range(30):\n",
    "    inputs, ys = get_citibike_data()\n",
    "    ys[ys>2000] = 2000\n",
    "    ys[ys<0]= 0\n",
    "\n",
    "    ys_mean = np.mean(ys)\n",
    "    ys_std = np.std(ys)\n",
    "    ys = ys - ys_mean\n",
    "    ys = ys / ys_std\n",
    "\n",
    "    training_inputs = inputs[0:-100,:]\n",
    "    training_ys = ys[0:-100][:,None]\n",
    "    test_inputs = inputs[-100:,:]\n",
    "    test_ys = ys[-100:][:,None]\n",
    "\n",
    "    test_inputs = inputs[-100:,:]\n",
    "    test_ys = ys[-100:][:,None]\n",
    "\n",
    "    results = {}\n",
    "\n",
    "    for steps in [3,6,10]:\n",
    "        results[steps] = {} \n",
    "        for eps in [0.2,0.5,1.0,1000]:\n",
    "            print \"Steps = %d, eps = %0.1f\" % (steps,eps)\n",
    "            if eps>100:\n",
    "                sens = 0\n",
    "            else:\n",
    "                sens = 2000\n",
    "            kernvar = 10.0\n",
    "            kern_ls = np.array([0.01,0.01,0.01,0.01])*1.0\n",
    "\n",
    "\n",
    "            sens = sens / ys_std\n",
    "\n",
    "            labels = [\"Histogram\"]\n",
    "\n",
    "            preds, cov = get_hist_prediction(training_inputs,training_ys,test_inputs,sens,eps,0.01,10.0,1.0, kernvar, kern_ls, steps)\n",
    "            RMSE = np.sqrt(np.mean((test_ys-preds)**2))\n",
    "            results[steps][eps] = {'label':label, 'preds':preds, 'cov':cov, 'RMSE':RMSE, 'ys_std':ys_std}\n",
    "    v = []\n",
    "    for j in np.sort(results.keys()):\n",
    "        for k in np.sort(results[j].keys())[::-1]:\n",
    "            #print str(j)+\",\"+str(k)+\":\",\n",
    "            #print str(results[j][k]['RMSE']*results[j][k]['ys_std'])+\",\",\n",
    "            v.append(results[j][k]['RMSE']*results[j][k]['ys_std']) \n",
    "    vs.append(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3,1000.0: 626.930832709, 3,1.0: 659.28615086, 3,0.5: 656.084486665, 3,0.2: 781.520064025,\n"
     ]
    }
   ],
   "source": [
    "for j in np.sort(results.keys()):\n",
    "    for k in np.sort(results[j].keys())[::-1]:\n",
    "        print str(j)+\",\"+str(k)+\":\",\n",
    "        print str(results[j][k]['RMSE']*results[j][k]['ys_std'])+\",\",\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  597.49867664,   866.92360136,   914.87441455],\n",
       "       [  556.51963002,   573.17012207,   566.6756472 ],\n",
       "       [  580.80305628,   762.08541878,  1614.43088419],\n",
       "       [  562.38447   ,   625.89161002,   649.45262003],\n",
       "       [  626.93083271,   659.28615086,   656.08448667]])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(vs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
