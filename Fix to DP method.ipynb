{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "warning in stationary: failed to import cython module: falling back to numpy\n"
     ]
    }
   ],
   "source": [
    "import GPy\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "np.set_printoptions(suppress=True,precision=3)\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We begin with $A$, the initial kernel (covariance) matrix.\n",
    "For convenience $A$ includes the covariance between three points, two training (at x[0] and x[2]) and we later reuse the training points as test points (x[:])."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "A = np.zeros([3,3])\n",
    "x = np.array([1,2,3])\n",
    "for i in range(3):\n",
    "    for j in range(3):\n",
    "        A[i,j] = np.exp(-(x[i]-x[j])**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.   ,  0.368,  0.018],\n",
       "       [ 0.368,  1.   ,  0.368],\n",
       "       [ 0.018,  0.368,  1.   ]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we slice up A into the covariance between training points $K$, and between training and test points $K_*$. $\\mathbf{y}$ is the training output values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "K = A[[0,2],:][:,[0,2]]\n",
    "K_star = A[:,[0,2]]\n",
    "y = np.array([1,2])-1.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.     0.018]\n",
      " [ 0.018  1.   ]]\n",
      "[[ 1.     0.018]\n",
      " [ 0.368  0.368]\n",
      " [ 0.018  1.   ]]\n"
     ]
    }
   ],
   "source": [
    "print K\n",
    "print K_star"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The DP bit\n",
    "\n",
    "Here we find the bound on the sensitivity, \"scale\". We scale our covariances $A$ with this scale, so that the variance at the relevant locations is scaled appropriately. Previously we wanted to try and scale the sample for each test point, this isn't valid, so instead we are scaling the variance of each test point in the GP's covariance function.\n",
    "\n",
    "To generate the noise using the cloaking idea; I'm scaling a sample $G(\\mathbf{x_*})$ from a zero-mean GP by some function $\\mathbf{\\Delta}(\\mathbf{x})$. The test points vector of $D=\\text{diag}(\\mathbf{\\Delta}(\\mathbf{x_*}))$ can be represented directly as samples from a GP with zero-mean and a covariance of $K_{new} = D K D^T$.\n",
    "\n",
    "Can we actually write the above GP's kernel we are going to use as a non-stationary kernel (with a covariance that depends in some way on $x$ and $x'$), (but still with zero mean) such that the scale of the variance for any sample will be greater than $\\Delta(x)$ for all x. Then we use this kernel to start again: \n",
    "\n",
    "   a. make predictions (as normal using the training and test data), then \n",
    "   b. use it to generate the DP noise (as we're still now in the same RKHS).\n",
    "   \n",
    "Although we are now using a constant $\\Delta$, the kernel covariance function will have small values around our training data. I don't know if that will definitely work, as we will still be restricted by a potentially still quite brutal bound on $\\Delta$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "scale = np.max(np.abs(np.dot(K_star,np.linalg.inv(K))),1)\n",
    "A = np.dot(np.dot(np.diag(scale),A),np.diag(scale))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.     0.361  1.   ]\n"
     ]
    }
   ],
   "source": [
    "print scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.   ,  0.133,  0.018],\n",
       "       [ 0.133,  0.131,  0.133],\n",
       "       [ 0.018,  0.133,  1.   ]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "K = A[[0,2],:][:,[0,2]]\n",
    "k_star = A[1,[0,2]]\n",
    "k_star = A[0,[0,2]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ensure prediction still works with the new funky kernel;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.49999999999999994"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.dot(np.dot(k_star.T,np.linalg.inv(K)),y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The noise we need to add is far less,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.   ,  0.131,  1.   ])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.diag(A)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "only 0.13 compared to the noise at the two other points of 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXwAAAEACAYAAACwB81wAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fa88d8e3350>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "noise = []\n",
    "for it in range(1000):\n",
    "    noise.append(np.random.multivariate_normal(np.zeros(1),A[1,1][None,None]))\n",
    "noise = np.array(noise)\n",
    "plt.hist(noise);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
