{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . [ 8.52903336  2.67951518  3.70041609  2.15349431]\n"
     ]
    }
   ],
   "source": [
    "import dp4gp_datasets\n",
    "import dp4gp\n",
    "import random\n",
    "import numpy as np\n",
    "import GPy\n",
    "import matplotlib.pyplot as plt\n",
    "import dp4gp_histogram\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_score # http://scikit-learn.org/stable/developers/contributing.html#estimators\n",
    "from sklearn.base import BaseEstimator\n",
    "from sklearn.utils.validation import check_X_y, check_array, check_is_fitted\n",
    "from sklearn.cluster import KMeans\n",
    "%matplotlib inline\n",
    "\n",
    "kung = dp4gp_datasets.load_kung()\n",
    "\n",
    "def dp_unnormalise(y,normalisation_parameters):\n",
    "    y = y * normalisation_parameters['std']\n",
    "    y = y + normalisation_parameters['mean']\n",
    "    return y\n",
    "    \n",
    "def dp_normalise(y, sensitivity, clip='midpoint'):\n",
    "    \"\"\"new_y,actual_sensitivity,normalisation_parameters = dp_normalise(y, sensitivity)\n",
    "    \n",
    "    Normalises the data to have outputs mean zero, std one.\n",
    "    It also clips the data to lie within half the sensitivity\n",
    "    of the data's mid point*, thus inforcing the DP assumptions\n",
    "    for the sensitivity.\n",
    "    \n",
    "    *This behaviour can be modified or disabled by setting the clip parameter:\n",
    "      - None                = don't clip\n",
    "      - 'midpoint' (default) = a point halfway between the max and min values\n",
    "      - 'mean'               = use the mean\n",
    "      - 'median'             = use the median\n",
    "    \n",
    "    The method returns the new y values, the new sensitivity (in the now\n",
    "    normalised range), and a dictionary of the mean and std to allow future\n",
    "    unnormalisation\"\"\"\n",
    "    \n",
    "    if clip is not None:\n",
    "        middley = None\n",
    "        if clip=='midpoint': middley = (np.max(y)+np.min(y))/2\n",
    "        if clip=='mean': middley = np.mean(y)\n",
    "        if clip=='median': middley = np.median(y)\n",
    "        assert middley is not None, \"clip option invalid\"\n",
    "        \n",
    "        y[y>middley+sensitivity/2] = middley+sensitivity/2\n",
    "        y[y<middley-sensitivity/2] = middley-sensitivity/2\n",
    "\n",
    "    #normalise...\n",
    "    normalisation_parameters = {}\n",
    "    normalisation_parameters['mean'] = np.mean(y)\n",
    "    #ysub = (max(y)+min(y))/2.0 #todo decide what's best to use here...\n",
    "    new_y = y - normalisation_parameters['mean']\n",
    "    normalisation_parameters['std'] = np.std(y)\n",
    "    new_y = new_y / normalisation_parameters['std']\n",
    "    actual_sensitivity = sensitivity/normalisation_parameters['std']\n",
    "    return new_y,actual_sensitivity,normalisation_parameters\n",
    "\n",
    "class DPCloaking(BaseEstimator):\n",
    "    def __init__(self, kern=None, sensitivity=1.0, epsilon=1.0, delta=0.01, inducing=None):\n",
    "        \"\"\"\n",
    "        kern = a GPy kernel, Default: uses a default 1d RBF kernel, with default hyperparameters if not specified.\n",
    "        inducing = locations of inducing points, default to None - not using inducing points.\n",
    "        \"\"\"\n",
    "        self.kern = kern\n",
    "        self.sensitivity = sensitivity\n",
    "        self.epsilon = epsilon\n",
    "        self.delta = delta\n",
    "        self.inducing = inducing\n",
    "        \n",
    "    def fit(self, X, y, **kwargs):    \n",
    "        if self.kern is None:\n",
    "            self.kern = GPy.kern.RBF(1.0)\n",
    "        if self.inducing is None:\n",
    "            self.model = GPy.models.GPRegression(X,y,kern,normalizer=None)\n",
    "            self.dpgp = dp4gp.DPGP_cloaking(self.model,self.sensitivity,self.epsilon,self.delta)\n",
    "        else:\n",
    "            if isinstance(self.inducing, list):\n",
    "                inducinglocs = self.inducing\n",
    "            else:\n",
    "                inducinglocs = KMeans(n_clusters=self.inducing, random_state=0).fit(X).cluster_centers_\n",
    "            self.model = GPy.models.SparseGPRegression(X,y,kern,normalizer=None,Z=inducinglocs)\n",
    "            self.dpgp = dp4gp.DPGP_inducing_cloaking(self.model,self.sensitivity,self.epsilon,self.delta)\n",
    "        return self\n",
    "\n",
    "    def predict(self, X, Nattempts=2, Nits=5): #todo set Nits back to a larger value (e.g. 100)\n",
    "        print(\".\"),\n",
    "        ypred,_,_= self.dpgp.draw_prediction_samples(X,Nattempts=Nattempts,Nits=Nits)\n",
    "        return ypred\n",
    "\n",
    "y,ac_sens,norm_params = dp_normalise(kung[kung[:,3]==0,0:1],100.0)\n",
    "X = kung[kung[:,3]==0,1:3]\n",
    "epsilon = 1.0\n",
    "delta = 0.01\n",
    "\n",
    "kern = GPy.kern.RBF(2.0,lengthscale=25.0,variance=1.0)\n",
    "p_grid = {\"kern\":[]}\n",
    "for ls in 5.0**np.arange(0,2): #0 to 4\n",
    "    for v in 5.0**np.arange(-1,1): #-1 to 2\n",
    "        p_grid[\"kern\"].append(GPy.kern.RBF(2.0,lengthscale=ls,variance=v))\n",
    "\n",
    "clf = GridSearchCV(estimator=DPCloaking(sensitivity=ac_sens,kern=kern.copy()), param_grid=p_grid, scoring='neg_mean_squared_error', cv = 4)\n",
    "scores_normal = -cross_val_score(clf,X,y,scoring='neg_mean_squared_error',cv = 4)\n",
    "\n",
    "#unnormalise the RMSE\n",
    "print scores_normal\n",
    "scores_normal = dp_unnormalise(np.sqrt(np.mean(scores_normal)),norm_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "187.77081598342554"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores_normal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
